# ğŸŒ³ AgriGS-SLAM: Orchard Mapping Across Seasons via Multi-View Gaussian Splatting SLAM

![](img/cover.png)

> [!WARNING]
> The manuscript is currently under submission and revision. The source code will be released once the manuscript is accepted for publication.

> [!CAUTION]
> Temporary Citation (Preprint) - ArXiv: TODO

## ğŸ¯ Overview

AgriGS-SLAM is a Visualâ€“LiDAR SLAM framework designed for robust real-time 3D mapping and reconstruction in agricultural orchards. The system couples direct LiDAR odometry and loop closures with multi-camera 3D Gaussian Splatting (3DGS) rendering to handle the unique challenges of orchard environments, including repetitive row geometry, seasonal appearance changes, and wind-driven foliage motion.

## ğŸšœ Key Features

- **ğŸŒ¾ Multi-Modal Perception**: Fuses visual and LiDAR data for robust odometry and mapping
- **ğŸ›°ï¸ Real-Time 3D Reconstruction**: Leverages 3D Gaussian Splatting (3DGS) for efficient high-quality rendering
- **ğŸ Seasonal Robustness**: Demonstrated across dormancy, flowering, and harvesting periods in apple and pear orchards
- **ğŸ’¾ Memory-Efficient**: Unified gradient-driven map lifecycle preserves fine details while maintaining bounded memory consumption
- **ğŸ“ Geometry-Appearance Coupling**: Probabilistic depth consistency term refines poses and tightens sensor fusion
- **ğŸ“Š Standardized Evaluation**: Evaluates both training-view and novel-view synthesis to reduce 3DGS overfitting

## ğŸ“ Abstract

Autonomous robots in orchards require real-time
3D scene understanding despite repetitive row geometry, seasonal appearance changes, and wind-driven foliage motion. We present AgriGS-SLAM, a Visualâ€“LiDAR SLAM framework that couples direct LiDAR odometry and loop closures with multi-camera 3D Gaussian Splatting (3DGS) rendering. Batch rasterization across complementary viewpoints recovers orchard structure under occlusions, while a unified gradientdriven map lifecycle executed between keyframes preserves fine details and bounds memory. Pose refinement is guided by a probabilistic LiDAR-based depth consistency term, backpropagated through the camera projection to tighten geometryappearance coupling. We deploy the system on a field platform in apple and pear orchards across dormancy, flowering, and harvesting, using a standardized trajectory protocol that evaluates both training-view and novel-view synthesis to reduce 3DGS overfitting in evaluation. Across seasons and sites, AgriGS-SLAM delivers sharper, more stable reconstructions and steadier trajectories than recent state-of-the-art 3DGSSLAM baselines while maintaining real-time performance ontractor. While demonstrated in orchard monitoring, the approach can be applied to other outdoor domains requiring
robust multimodal perception.

##  ğŸ“š Citation

If you find this work useful, please cite it once available:

```bibtex
@article{usuelli2024agrigsslam,
  ... TODO
}
```

## ğŸ‘¨â€ğŸŒ¾ Authors

- **Mirko Usuelli**Â¹* and **Matteo Matteucci**Â¹  
  Dipartimento di Bioingegneria, Elettronica e Informazione, Politecnico di Milano, 20133 Milano, Italy  
  {mirko.usuelli, matteo.matteucci}@polimi.it

- **David Rapado-Rincon**Â² and **Gert Kootstra**Â²  
  Agricultural Biosystems Engineering, Wageningen University & Research, 6708 PB Wageningen, The Netherlands  
  {david.rapadorincon, gert.kootstra}@wur.nl

*Corresponding author

## ğŸ™ Acknowledgments

The authors thank the Fruit Research Center (FRC) in Randwijk for access to the orchards. Mirko Usuelli's work was carried out within the Agritech National  Research Center and funded by the EU Next-GenerationEU (PNRR â€“ M4C2, Inv. 1.4 â€“ D.D. 1032 17/06/2022, CN00000022). This manuscript reflects only the authors' views; the EU and Commission are not responsible. Contributions from Matteo Matteucci, Gert Kootstra, and David Rapado-Rincon were co-funded by the EU Digital Europe Programme (AgrifoodTEF, GA NÂº 101100622).